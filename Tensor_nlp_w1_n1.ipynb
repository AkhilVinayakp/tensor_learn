{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor_nlp_w1_n1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNnMqGO/xQU7JpMDMKIXeti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilVinayakp/tensor_learn/blob/master/Tensor_nlp_w1_n1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Ams8korGI8"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anYChH3IrfzI"
      },
      "source": [
        "sentences = ['I love my country', ' I love Rosses', ' The. Dark Crystal ', ' designated survivor', ' tensor!!!!!!','ten2']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mLegie4rxq4",
        "outputId": "427128b7-e851-473c-a573-cb4e48bd66b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'country': 4, 'rosses': 5, 'the': 6, 'dark': 7, 'crystal': 8, 'designated': 9, 'survivor': 10, 'tensor': 11, 'ten2': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p4J_4OrsLHA"
      },
      "source": [
        "# generating sequences using text_to_sequence method of tokenizer which is already fitted on list of sentences"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2JbBYW0u17E",
        "outputId": "c392b885-1232-43b7-d252-acac7d2fcdf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = Tokenizer(num_words=15)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'country': 4, 'rosses': 5, 'the': 6, 'dark': 7, 'crystal': 8, 'designated': 9, 'survivor': 10, 'tensor': 11, 'ten2': 12}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr4y_eJzww_o",
        "outputId": "55ec77ca-bd50-4b53-fb5b-e39dede2603a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.texts_to_matrix(sentences, mode='count')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q139j6egvvwo"
      },
      "source": [
        "list2 = ['Docker is awsome', 'Dark materials', 'i love crystel']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaU5ONJ1wPZo",
        "outputId": "23a058ad-ede6-491a-b3b7-648822bdeabf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# generating sequences using the index of words already defined in tokenizer object : \n",
        "tokenizer.texts_to_sequences(list2)\n",
        "#"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[], [7], [1, 2]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7Y6h_fwkOc",
        "outputId": "9b4e1a4f-be9d-403e-897c-3da00937b345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.texts_to_sequences(sentences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4], [1, 2, 5], [6, 7, 8], [9, 10], [11], [12]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bUfBwQk3Svk"
      },
      "source": [
        "# applying the padding to make each sequence of the same length\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC9YP2YKBIQo"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences=sequences)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8meKb79HB4Qg",
        "outputId": "2c874a33-2341-45e8-bca4-b59835704235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "padded"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  2,  3,  4],\n",
              "       [ 0,  1,  2,  5],\n",
              "       [ 0,  6,  7,  8],\n",
              "       [ 0,  0,  9, 10],\n",
              "       [ 0,  0,  0, 11],\n",
              "       [ 0,  0,  0, 12]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WivDq39B52E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}